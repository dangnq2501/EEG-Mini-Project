{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9810623,"sourceType":"datasetVersion","datasetId":5998417}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install mne\n!pip install optuna pytorch_lightning\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import mne\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\nfile_paths = [f\"/kaggle/input/eeg-signal/BCICIV_2a_gdf/A0{i}T.gdf\" for i in range(1, 10)]  \n\nall_data = []\nall_labels = []\n\nevent_ids = {\n    'left_hand': 7,   \n    'right_hand': 8,   \n    'feet': 9,         \n    'tongue': 10       \n}\n\nfor file_path in file_paths:\n    raw = mne.io.read_raw_gdf(file_path, preload=True)\n    raw.notch_filter(freqs=50)# Notch filter\n    raw.filter(8., 30., fir_design='firwin')#Band-Pass Filter to Retain Frequencies of Interest\n    raw.set_eeg_reference('average')# Re-reference the EEG Signals\n    \n    events, event_dict = mne.events_from_annotations(raw)\n    print(f\"Available events in {file_path}: {event_dict}\")\n    \n    available_event_ids = {key: event_ids[key] for key in event_ids if event_ids[key] in event_dict.values()}\n    \n    if not available_event_ids:\n        print(f\"No motor imagery tasks found in {file_path}. Skipping this file.\")\n        continue  \n    \n    epochs = mne.Epochs(raw, events, event_id=available_event_ids, tmin=0, tmax=4, baseline=None, preload=True)\n    \n    X = epochs.get_data() \n    X_normalized = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n    y = epochs.events[:, -1] - min(available_event_ids.values())  \n    \n    all_data.append(X_normalized)\n    all_labels.append(y)\n\nX_combined = np.concatenate(all_data, axis=0) \ny_combined = np.concatenate(all_labels, axis=0)  \n\nX_tensor = torch.tensor(X_combined, dtype=torch.float32).unsqueeze(1) \ny_tensor = torch.tensor(y_combined, dtype=torch.long)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ratio = 0.8\nN = len(X_tensor)\nidx = np.arange(N)\nnp.random.shuffle(idx)\n\ntrain_size = int(N * train_ratio)\ntrain_idx = idx[:train_size]\nval_idx = idx[train_size:]\n\nX_train = X_tensor[train_idx]\ny_train = y_tensor[train_idx]\n\nX_val = X_tensor[val_idx]\ny_val = y_tensor[val_idx]\n\ntrain_dataset = TensorDataset(X_train, y_train)\nval_dataset = TensorDataset(X_val, y_val)\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n\n\nclass EEGAutoencoder(nn.Module):\n    def __init__(self, n_channels=22, n_times=1001, latent_dim=64):\n        super(EEGAutoencoder, self).__init__()\n        self.n_channels = n_channels\n        self.n_times = n_times\n        input_dim = n_channels * n_times\n        \n        self.encoder = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(input_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, latent_dim)\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, input_dim),\n        )\n        \n    def forward(self, x):\n        z = self.encoder(x)\n        x_recon = self.decoder(z)\n        x_recon = x_recon.view(-1, 1, self.n_channels, self.n_times)\n        return x_recon, z\n\nn_channels = X_tensor.shape[2]\nn_times = X_tensor.shape[3]\nlatent_dim = 64\nae = EEGAutoencoder(n_channels=n_channels, n_times=n_times, latent_dim=latent_dim)\nae_optimizer = optim.Adam(ae.parameters(), lr=1e-3)\nae_criterion = nn.MSELoss()\n\n\nnum_epochs_ae = 50\nfor epoch in range(num_epochs_ae):\n    ae.train()\n    total_loss = 0.0\n    for X_batch, _ in train_loader:\n        ae_optimizer.zero_grad()\n        X_recon, _ = ae(X_batch)\n        loss = ae_criterion(X_recon, X_batch)\n        loss.backward()\n        ae_optimizer.step()\n        total_loss += loss.item()\n    print(f\"AE Epoch {epoch+1}/{num_epochs_ae}, Loss: {total_loss/len(train_loader):.4f}\")\n\nae.eval()\nwith torch.no_grad():\n    train_features = []\n    train_labels = []\n    for X_batch, y_batch in train_loader:\n        _, z = ae(X_batch)\n        train_features.append(z)\n        train_labels.append(y_batch)\n    train_features = torch.cat(train_features, dim=0)\n    train_labels = torch.cat(train_labels, dim=0)\n    \n    val_features = []\n    val_labels = []\n    for X_batch, y_batch in val_loader:\n        _, z = ae(X_batch)\n        val_features.append(z)\n        val_labels.append(y_batch)\n    val_features = torch.cat(val_features, dim=0)\n    val_labels = torch.cat(val_labels, dim=0)\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nclass CombinedDataset(torch.utils.data.Dataset):\n    def __init__(self, raw_data, raw_labels, ae_features):\n        self.raw_data = raw_data\n        self.ae_features = ae_features\n        self.raw_labels = raw_labels\n\n    def __len__(self):\n        return len(self.raw_labels)\n\n    def __getitem__(self, idx):\n        return self.raw_data[idx], self.ae_features[idx], self.raw_labels[idx]\n\ntrain_combined_dataset = CombinedDataset(X_train, y_train, train_features)\nval_combined_dataset = CombinedDataset(X_val, y_val, val_features)\n\ntrain_loader = DataLoader(train_combined_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_combined_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(y_train.unique(return_counts=True))\nprint(y_val.unique(return_counts=True))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_feat_dataset = TensorDataset(train_features, train_labels)\n# val_feat_dataset = TensorDataset(val_features, val_labels)\n# batch_size = 64\n# train_feat_loader = DataLoader(train_feat_dataset, batch_size=batch_size, shuffle=True)\n# val_feat_loader = DataLoader(val_feat_dataset, batch_size=batch_size, shuffle=False)\nimport pytorch_lightning as pl\n\n\nclass MultiBranchLightningModule(pl.LightningModule):\n    def __init__(self, \n                 latent_dim=64, \n                 n_channels=22, \n                 n_times=1001, \n                 num_classes=4, \n                 dropout_rate=0.3, \n                 hidden_dim=64, \n                 lr=1e-3, \n                 criterion='crossentropy'):\n        super().__init__()\n        self.save_hyperparameters()\n\n        # Choose criterion\n        if criterion == 'crossentropy':\n            self.criterion = nn.CrossEntropyLoss()\n        elif criterion == 'mse':\n            self.criterion = nn.MSELoss()\n        else:\n            raise ValueError(\"Unknown criterion\")\n\n        # CNN branch for raw EEG\n        self.cnn_branch = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=(3,3), padding=1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d((2,2)),\n            nn.Dropout(dropout_rate),\n\n            nn.Conv2d(16, 32, kernel_size=(3,3), padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d((2,2)),\n            nn.Dropout(dropout_rate),\n            nn.Flatten()\n        )\n\n        n_channels_out = n_channels // 4\n        n_times_out = n_times // 4\n        cnn_output_dim = 48000\n\n        self.ae_branch = nn.Sequential(\n            nn.Linear(latent_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate)\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Linear(cnn_output_dim + hidden_dim, 32),\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(32, num_classes)\n        )\n\n    def forward(self, x_raw, x_ae):\n        out_cnn = self.cnn_branch(x_raw)   # [B, cnn_output_dim]\n        out_ae = self.ae_branch(x_ae)      # [B, hidden_dim]\n        # print(out_cnn.shape, out_ae.shape)\n        out = torch.cat((out_cnn, out_ae), dim=1) \n        logits = self.classifier(out)\n        return logits\n\n    def training_step(self, batch, batch_idx):\n        X_batch, Z_batch, y_batch = batch\n        logits = self(X_batch, Z_batch)\n\n        if self.hparams.criterion == 'crossentropy':\n            loss = self.criterion(logits, y_batch)\n        elif self.hparams.criterion == 'mse':\n            num_classes = logits.shape[1]\n            y_one_hot = torch.zeros(y_batch.size(0), num_classes, device=y_batch.device)\n            y_one_hot.scatter_(1, y_batch.unsqueeze(1), 1.0)\n            loss = self.criterion(logits, y_one_hot)\n        else:\n            raise ValueError(\"Unknown criterion\")\n\n        self.log('train_loss', loss, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        X_batch, Z_batch, y_batch = batch\n        logits = self(X_batch, Z_batch)\n\n        if self.hparams.criterion == 'crossentropy':\n            loss = self.criterion(logits, y_batch)\n        elif self.hparams.criterion == 'mse':\n            num_classes = logits.shape[1]\n            y_one_hot = torch.zeros(y_batch.size(0), num_classes, device=y_batch.device)\n            y_one_hot.scatter_(1, y_batch.unsqueeze(1), 1.0)\n            loss = self.criterion(logits, y_one_hot)\n        else:\n            raise ValueError(\"Unknown criterion\")\n\n        preds = torch.argmax(logits, dim=1)\n        acc = (preds == y_batch).float().mean()\n        self.log('val_loss', loss, prog_bar=True)\n        self.log('val_acc', acc, prog_bar=True, on_epoch=True) \n        return {'val_loss': loss, 'val_acc': acc, 'preds': preds, 'targets': y_batch}\n\n\n    def configure_optimizers(self):\n        return optim.Adam(self.parameters(), lr=self.hparams.lr)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nimport optuna\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = MultiBranchLightningModule(\n            latent_dim=latent_dim, \n            n_channels=22, \n            n_times=1001, \n            num_classes=4, \n            hidden_dim=best_params['hidden_dim'],\n            dropout_rate=best_params['dropout_rate'],\n            lr=best_params['lr'],\n            criterion=best_params['criterion']\n            )\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor='val_acc',\n    mode='max',\n    save_top_k=1,\n    filename='best-checkpoint-{epoch:02d}-{val_acc:.2f}'\n)\n\ntrainer = pl.Trainer(\n    max_epochs=40,\n    callbacks=[checkpoint_callback],\n    enable_progress_bar=False,\n    log_every_n_steps=1\n)\ntrainer.fit(model, train_loader, val_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\nall_preds = []\nall_targets = []\n\nwith torch.no_grad():\n    for X_batch, Z_batch, y_batch in val_loader:\n        logits = model(X_batch, Z_batch)  \n        preds = torch.argmax(logits, dim=1)\n        \n        all_preds.append(preds.cpu())\n        all_targets.append(y_batch.cpu())\n\nall_preds = torch.cat(all_preds)\nall_targets = torch.cat(all_targets)\n\ncm = confusion_matrix(all_targets.numpy(), all_preds.numpy())\n\nfig, ax = plt.subplots(figsize=(5, 5))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap=plt.cm.Blues, ax=ax)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ndef objective(trial):\n    hidden_dim = trial.suggest_int('hidden_dim', 32, 256, step=32)\n    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5, step=0.1)\n    lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n    criterion_choice = trial.suggest_categorical('criterion', ['crossentropy', 'mse'])\n\n    model = MultiBranchLightningModule(\n                 latent_dim=latent_dim, \n                 n_channels=22, \n                 n_times=1001, \n                 num_classes=4, \n                 dropout_rate=dropout_rate, \n                 hidden_dim=hidden_dim, \n                 lr=lr, \n                 criterion=criterion_choice)\n\n    checkpoint_callback = ModelCheckpoint(\n        monitor='val_acc',\n        mode='max',\n        save_top_k=1,\n        filename='best-checkpoint-{epoch:02d}-{val_acc:.2f}'\n    )\n\n    trainer = pl.Trainer(\n        max_epochs=50,\n        callbacks=[checkpoint_callback],\n        enable_progress_bar=False,\n        log_every_n_steps=1\n    )\n\n    trainer.fit(model, train_loader, val_loader)\n    return trainer.callback_metrics['val_acc'].item()\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)\n\nprint(\"Best trial:\")\ntrial = study.best_trial\nprint(f\"  Value: {trial.value}\")\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(f\"    {key}: {value}\")\n\nbest_params = study.best_params\n\nbest_model = MultiBranchLightningModule(\n            latent_dim=latent_dim, \n            n_channels=22, \n            n_times=1001, \n            num_classes=4, \n            hidden_dim=best_params['hidden_dim'],\n            dropout_rate=best_params['dropout_rate'],\n            lr=best_params['lr'],\n            criterion=best_params['criterion']\n            )\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor='val_acc',\n    mode='max',\n    save_top_k=1,\n    filename='best-checkpoint-{epoch:02d}-{val_acc:.2f}'\n)\n\ntrainer = pl.Trainer(\n    max_epochs=50,\n    callbacks=[checkpoint_callback],\n    enable_progress_bar=False,\n    log_every_n_steps=1\n)\n\nbest_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T08:51:45.612036Z","iopub.execute_input":"2024-12-15T08:51:45.612320Z"}},"outputs":[{"name":"stderr","text":"[I 2024-12-15 08:51:45,616] A new study created in memory with name: no-name-c4b7c1c2-6d17-460d-921e-6f449b584158\n[I 2024-12-15 09:18:17,459] Trial 0 finished with value: 0.37142857909202576 and parameters: {'hidden_dim': 192, 'dropout_rate': 0.5, 'lr': 6.286522302899363e-05, 'criterion': 'crossentropy'}. Best is trial 0 with value: 0.37142857909202576.\n[I 2024-12-15 09:45:20,352] Trial 1 finished with value: 0.45102041959762573 and parameters: {'hidden_dim': 160, 'dropout_rate': 0.1, 'lr': 2.1321485898878236e-05, 'criterion': 'crossentropy'}. Best is trial 1 with value: 0.45102041959762573.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\nall_preds = []\nall_targets = []\n\nwith torch.no_grad():\n    for X_batch, Z_batch, y_batch in val_loader:\n        logits = best_model(X_batch, Z_batch)  \n        preds = torch.argmax(logits, dim=1)\n        \n        all_preds.append(preds.cpu())\n        all_targets.append(y_batch.cpu())\n\nall_preds = torch.cat(all_preds)\nall_targets = torch.cat(all_targets)\n\ncm = confusion_matrix(all_targets.numpy(), all_preds.numpy())\n\nfig, ax = plt.subplots(figsize=(5, 5))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap=plt.cm.Blues, ax=ax)\nplt.title('Confusion Matrix - Best Hyperparameters')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}